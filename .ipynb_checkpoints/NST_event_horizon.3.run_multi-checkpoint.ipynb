{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "responsible-berlin",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now running many experiments and doing analyses on them all\n",
    "\n",
    "from neuron import h\n",
    "from neuron.units import mV, ms\n",
    "h.load_file('stdrun.hoc')\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import math\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "color-sessions",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_histories(sim_length = 10000, stim_interval = 10, num_histories = 1000):\n",
    "\n",
    "    # Set up biophysical model\n",
    "    axon = h.Section(name='axon')\n",
    "    axon.insert(h.hh)\n",
    "\n",
    "    # add a synapse\n",
    "    syn = h.ExpSyn(axon(0))\n",
    "    syn.tau = 1 * ms\n",
    "    syn.e = 0 * mV\n",
    "    syn_current = h.Vector().record(syn._ref_i)\n",
    "\n",
    "    # add a stimulus\n",
    "    stim = h.NetStim()\n",
    "    stim.number = 9999999\n",
    "    stim.interval = stim_interval * ms\n",
    "    stim.noise = True\n",
    "    stim.start = 0 * ms\n",
    "\n",
    "    stim_times = h.Vector()\n",
    "\n",
    "    # connect stimulus to synapse\n",
    "    nc = h.NetCon(stim, syn)\n",
    "    nc.delay = 0 * ms\n",
    "    nc.weight[0] = 0.2\n",
    "    nc.record(stim_times)\n",
    "\n",
    "    # setup recording\n",
    "    _t = h.Vector().record(h._ref_t)\n",
    "    _v = h.Vector().record(axon(0.5)._ref_v)\n",
    "    _m = h.Vector().record(axon(0.5).hh._ref_m)\n",
    "    _n = h.Vector().record(axon(0.5).hh._ref_n)\n",
    "    _h = h.Vector().record(axon(0.5).hh._ref_h)\n",
    "    spike_times = h.Vector()\n",
    "    nc_self = h.NetCon(axon(0.5)._ref_v, None, sec=axon)\n",
    "    nc_self.record(spike_times)\n",
    "\n",
    "    # run simulation\n",
    "    h.finitialize(-65 * mV)\n",
    "    h.continuerun(sim_length * ms)\n",
    "    \n",
    "    histories = np.array((_v, _m, _h, _n))[:, random.sample(range(0, len(_v)), num_histories)]\n",
    "\n",
    "    return histories, np.array((_t, _v, _m, _h, _n, syn_current)), list(spike_times), list(stim_times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "rational-restoration",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up preceding stim times for event horizon experiment (based on output spike)\n",
    "\n",
    "def gen_preceding_stims(pivot_ind, spike_times, num_history_stims = 10):\n",
    "    # num_history_stims: this is the number of stims to include in the experiment's history\n",
    "    # pivot_ind: which output spike to use as pivot\n",
    "\n",
    "    # choose output spike as pivot\n",
    "    pivot = spike_times[pivot_ind]\n",
    "\n",
    "    # isolate the stimuli preceding the pivot spike\n",
    "    preceding_stims = [st for st in stim_times if st < pivot]\n",
    "    # check to make sure there are enough stims here\n",
    "    if len(preceding_stims) < num_history_stims:\n",
    "        return False, False\n",
    "    preceding_stims = preceding_stims[-num_history_stims:]\n",
    "\n",
    "    # set the last stimuli before the pivot spike as t0\n",
    "    pivot = pivot - preceding_stims[-1]\n",
    "    preceding_stims = [st - preceding_stims[-1] for st in preceding_stims]\n",
    "\n",
    "    # round stimuli and pivot to the nearest 1/40th ms\n",
    "    preceding_stims = [(math.floor(ps * 40))/40 for ps in preceding_stims]\n",
    "    pivot = (math.floor(pivot * 40))/40\n",
    "    \n",
    "    return preceding_stims, pivot\n",
    "\n",
    "def view_preceding_stimuli(preceding_stims, pivot):\n",
    "    # view the preceding stimuli\n",
    "    plt.figure(figsize = (15, 3))\n",
    "    plt.vlines(preceding_stims, 0, 1, color = 'black')\n",
    "    plt.vlines(pivot, 0, 1, color = 'red')\n",
    "    plt.xlabel('time (ms)')\n",
    "    plt.yticks([])\n",
    "    plt.show()\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "functional-cameroon",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize simulations with new initial conditions and custom stimuli\n",
    "def sim_init(axon, _v_init, _m_init, _h_init, _n_init):\n",
    "    for seg in axon:\n",
    "        seg.v = _v_init\n",
    "        seg.hh.m = _m_init\n",
    "        seg.hh.h = _h_init\n",
    "        seg.hh.n = _n_init\n",
    "\n",
    "def seed_sim(history, stimuli, sim_length = 100):\n",
    "    \n",
    "    # Set up biophysical model\n",
    "    axon = h.Section(name='axon')\n",
    "    axon.insert(h.hh)\n",
    "    \n",
    "    # add a synapse\n",
    "    syn = h.ExpSyn(axon(0))\n",
    "    syn.tau = 1 * ms\n",
    "    syn.e = 0 * mV\n",
    "    syn_current = h.Vector().record(syn._ref_i)\n",
    "    \n",
    "    # add custum stimuli\n",
    "    netstims = [h.NetStim() for stimulus in stimuli]\n",
    "    netcons = [] # store netcons here as they need to exist in memory to parallelize\n",
    "    for netstim, stimulus in zip(netstims, stimuli):\n",
    "        netstim.number = 1\n",
    "        netstim.start = stimulus\n",
    "        netcon = h.NetCon(netstim, syn)\n",
    "        netcon.weight[0] = 0.2\n",
    "        netcons.append(netcon)\n",
    "        \n",
    "        netcon.delay = 0 * ms \n",
    "\n",
    "    stim_times = h.Vector()\n",
    "\n",
    "    # setup recording\n",
    "    _t = h.Vector().record(h._ref_t)\n",
    "    _v = h.Vector().record(axon(0.5)._ref_v)\n",
    "    _m = h.Vector().record(axon(0.5).hh._ref_m)\n",
    "    _n = h.Vector().record(axon(0.5).hh._ref_n)\n",
    "    _h = h.Vector().record(axon(0.5).hh._ref_h)\n",
    "    \n",
    "    spike_times = h.Vector()\n",
    "    nc_self = h.NetCon(axon(0.5)._ref_v, None, sec=axon)\n",
    "    nc_self.record(spike_times)\n",
    "\n",
    "    # run simulation\n",
    "    \n",
    "    # initialize simulation\n",
    "    _v_init = history[0]\n",
    "    _m_init = history[1]\n",
    "    _h_init = history[2]\n",
    "    _n_init = history[3]\n",
    "    \n",
    "    fih = h.FInitializeHandler((sim_init,(axon, _v_init, _m_init, _h_init, _n_init)))\n",
    "    h.finitialize()\n",
    "    h.continuerun(sim_length * ms)\n",
    "    \n",
    "    return np.array((_t, _v, _m, _h, _n, syn_current)), list(spike_times)\n",
    "\n",
    "def run_simulation(stimuli, histories, extended_duration = 20):\n",
    "    # function to run a simulation with a given set of histories, a set of predetermined stimuli, and an extended duration\n",
    "    # extended_duration: amount of time after the last stimulus to run the experiment\n",
    "    \n",
    "    exp_out = []\n",
    "    \n",
    "    for i in range(histories.shape[1]):\n",
    "        history = histories[:,i]\n",
    "        sim_out, spike_times = seed_sim(history, stimuli, sim_length = extended_duration + stimuli[-1])\n",
    "        exp_out.append(spike_times)\n",
    "        \n",
    "    return exp_out\n",
    "\n",
    "def preceding_stims_walk(preceding_stims, histories):\n",
    "    # function to walk through each of the preceding stimuli\n",
    "    resulting_NSTs = [] # next-spike-times\n",
    "    resulting_PSTs = [] # pre-spike-times (those spikes that occur before the last stimulus)\n",
    "\n",
    "    for num_stims_included in range(1, len(preceding_stims) + 1):\n",
    "        current_stims = preceding_stims[len(preceding_stims) - num_stims_included:]\n",
    "\n",
    "        # set the first stim to t0\n",
    "        current_stims = [cs - current_stims[0] for cs in current_stims]\n",
    "\n",
    "        #print('number of preceding stims:', len(current_stims))\n",
    "        exp_out = run_simulation(current_stims, histories)\n",
    "        NSTs = [] # next-spike-times\n",
    "        PSTs = [] # pre-spike-times (those spikes that occur before the last stimulus)\n",
    "\n",
    "        # process each exp_out\n",
    "        for spike_times in exp_out:\n",
    "            # separate spike_times before and after the last stimulus\n",
    "            pre_spike_times = [sp for sp in spike_times if sp <= current_stims[-1]]\n",
    "            post_spike_times = [sp for sp in spike_times if sp > current_stims[-1]]\n",
    "            \n",
    "            #print(len(spike_times), len(pre_spike_times), len(post_spike_times))\n",
    "\n",
    "            if len(post_spike_times) > 0:\n",
    "                NSTs.append(post_spike_times[0])\n",
    "            else:\n",
    "                NSTs.append('na') # did not spike\n",
    "                \n",
    "            PSTs += pre_spike_times \n",
    "\n",
    "\n",
    "        # set the last stimulus to t0\n",
    "        _NSTs = []\n",
    "        for nst in NSTs:\n",
    "            if nst != 'na':\n",
    "                nst = nst - current_stims[-1]\n",
    "            _NSTs.append(nst)\n",
    "        \n",
    "        PSTs = [pst - current_stims[-1] for pst in PSTs]\n",
    "            \n",
    "        #NSTs = [nst - current_stims[-1] for nst in NSTs if nst != 'na']    \n",
    "        #print('number of NSTs:', len(NSTs))\n",
    "\n",
    "        resulting_NSTs.append(_NSTs)\n",
    "        resulting_PSTs.append(PSTs)\n",
    "        \n",
    "    return resulting_NSTs, resulting_PSTs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "theoretical-complexity",
   "metadata": {},
   "source": [
    "## Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "tested-amendment",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of histories: 1000\n",
      "number of spikes:  208\n"
     ]
    }
   ],
   "source": [
    "# generate histories\n",
    "\n",
    "# long run\n",
    "histories, sim_df, spike_times_initial, stim_times = gen_histories(sim_length = 10000, num_histories = 1000)\n",
    "\n",
    "# short run\n",
    "#histories, sim_df, spike_times_initial, stim_times = gen_histories(sim_length = 2000, num_histories = 10)\n",
    "\n",
    "print('number of histories:', histories.shape[1])\n",
    "print('number of spikes: ', len(spike_times_initial))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cleared-edition",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 / 208\n",
      "20 / 208\n",
      "30 / 208\n",
      "40 / 208\n",
      "50 / 208\n",
      "60 / 208\n",
      "70 / 208\n",
      "80 / 208\n",
      "90 / 208\n",
      "100 / 208\n",
      "110 / 208\n",
      "120 / 208\n",
      "130 / 208\n",
      "140 / 208\n",
      "150 / 208\n",
      "160 / 208\n",
      "170 / 208\n",
      "180 / 208\n",
      "190 / 208\n",
      "200 / 208\n"
     ]
    }
   ],
   "source": [
    "# generate preceding_stims sets\n",
    "\n",
    "'''\n",
    "# pick the pivot inds to use\n",
    "num_preceding_stims_sets = 100\n",
    "pivot_inds = random.sample(range(10, len(spike_times_initial)), num_preceding_stims_sets)\n",
    "'''\n",
    "\n",
    "# data dirs\n",
    "pstims_ext = './data/preceding_stims/'\n",
    "rNSTs_ext = './data/resulting_NSTs/'\n",
    "rPSTs_ext = './data/resulting_PSTs/'\n",
    "\n",
    "pivots = {}\n",
    "\n",
    "for i, pivot_ind in enumerate(range(len(spike_times_initial))):\n",
    "    # generate the preceding stims\n",
    "    preceding_stims, pivot = gen_preceding_stims(pivot_ind = pivot_ind, spike_times = spike_times_initial)\n",
    "    \n",
    "    # select all pivots that apply (have at least 10 preceding stimuli)\n",
    "    if preceding_stims == False:\n",
    "        #print(i, 'th pivot not acceptable')\n",
    "        pass\n",
    "    else:\n",
    "        pivots[pivot_ind] = pivot\n",
    "\n",
    "        # save preceding_stims to file\n",
    "        pstims_file = 'pstims' + str(i) + '.txt'\n",
    "        with open(pstims_ext + pstims_file, 'w') as writer:\n",
    "            for stim in preceding_stims:\n",
    "                writer.write(\"%s\\n\" % stim)\n",
    "\n",
    "        # run the preceding stims walk\n",
    "        resulting_NSTs, resulting_PSTs = preceding_stims_walk(preceding_stims, histories)\n",
    "\n",
    "        # save resulting_NSTs to file\n",
    "        rNSTs_file = 'rNSTs' + str(i)\n",
    "        rPSTs_file = 'rPSTs' + str(i) + '.pkl'\n",
    "        np.save(rNSTs_ext + rNSTs_file, np.array(resulting_NSTs))\n",
    "        with open(rPSTs_ext + rPSTs_file, 'wb') as f:\n",
    "            pickle.dump(resulting_PSTs, f)\n",
    "        \n",
    "        if (i+1) % 10 == 0:\n",
    "            print(i+1, '/', len(spike_times_initial))\n",
    "            \n",
    "# save pivots to file\n",
    "with open('./data/pivots.pkl', 'wb') as f:\n",
    "    pickle.dump(pivots, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c539558c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# takes about an hour or so to run"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
